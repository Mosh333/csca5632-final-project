{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ad340b9",
   "metadata": {},
   "source": [
    "# CSCA 5632 Final Project - Unsupervised and Supervised Learning on Animal Faces (AFHQ Dataset)\n",
    "### By Moshiur Howlader\n",
    "##### Github Link : https://github.com/Mosh333/csca5632-final-project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ff431e",
   "metadata": {},
   "source": [
    "### 1. Introduction\n",
    "\n",
    "In today’s data-driven world, the ability to **uncover structure and meaning from unlabeled data** represents one of the most powerful and important areas in machine learning.\n",
    "While supervised learning depends on extensive labeled datasets, many real-world domains contain **vast quantities of raw, unannotated information**—such as images, text, medical scans, or sensor data—where manual labeling is costly or infeasible.  \n",
    "Here, [**unsupervised learning**](https://biztechmagazine.com/article/2025/05/what-are-benefits-unsupervised-machine-learning-and-clustering-perfcon) plays a pivotal role: it enables algorithms to reveal hidden patterns, latent representations, and natural groupings within data without external supervision.\n",
    "\n",
    "Unsupervised learning drives [innovation across diverse domains](https://pmc.ncbi.nlm.nih.gov/articles/PMC7983091/):\n",
    "\n",
    "- [**Data exploration and pattern discovery:**](https://analyticalsciencejournals.onlinelibrary.wiley.com/doi/pdfdirect/10.1002/mas.21602) Enables open-ended analysis of large, high-dimensional datasets to uncover hidden structures, correlations, and trends—reducing dimensionality and aiding human interpretation, such as exploring mass spectrometry data across large experimental datasets.  \n",
    "- [**Computer vision:**](https://viso.ai/deep-learning/supervised-vs-unsupervised-learning/) Groups unlabeled images by similarity, compresses data via [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html), or learns visual embeddings through self-supervised methods like [SimCLR](https://arxiv.org/abs/2002.05709).  \n",
    "- [**Natural language processing:**](https://milvus.io/ai-quick-reference/what-is-the-role-of-unsupervised-learning-in-nlp) Learns semantic relationships in text through [Word2Vec](https://arxiv.org/abs/1301.3781) or discovers latent topics using [Latent Dirichlet Allocation (LDA)](https://jmlr.org/papers/v3/blei03a.html).  \n",
    "- [**Healthcare and biomedical research:**](https://pubmed.ncbi.nlm.nih.gov/31891765/) Facilitates the discovery of hidden disease patterns, comorbidity clusters, and patient subgroups from large-scale electronic health records—enabling better understanding of latent traits, risk domains, and disease progression, such as identifying novel comorbidity patterns in aging cohorts.  \n",
    "- [**Autonomous systems and robotics:**](https://fiveable.me/introduction-autonomous-robots/unit-7/unsupervised-learning/study-guide/rNorV1tsC0TeCPOO) Maps environments, groups sensor inputs, and learns spatial representations without labeled supervision.  \n",
    "- [**Recommender and personalization systems:**](https://www.mdpi.com/2073-8994/12/2/185) Clusters users or content to generate recommendations when explicit ratings are unavailable.\n",
    "\n",
    "Together, these examples highlight how unsupervised learning forms the foundation of **exploratory data analysis** and **representation learning**, allowing models to extract structure from raw data before labels exist.\n",
    "\n",
    "![Illustration of Unsupervised Learning Process - https://uk.mathworks.com/discovery/unsupervised-learning.html](../images/1-intro-pic.png)\n",
    "\n",
    "*Figure: Conceptual illustration of unsupervised learning — an algorithm groups unlabeled data points (shapes) based on similarity, forming meaningful clusters.*\n",
    "\n",
    "---\n",
    "\n",
    "#### 1.1 Project Overview and Objectives\n",
    "Here we discuss the selected data source and the unsupervised learning problem we aim to solve.\n",
    "\n",
    "#### 1.2 Gather Data, Determine the Method of Data Collection and Provenance\n",
    "This project uses the **[Animal Faces-HQ (AFHQ) dataset](https://www.kaggle.com/datasets/andrewmvd/animal-faces)** — a publicly available image dataset originally curated by **Andrew Mvd** on Kaggle under a **CC BY-NC license**.  \n",
    "AFHQ contains **over 16,000 high-quality animal face images** across three balanced categories: **cats, dogs, and wildlife**.\n",
    "\n",
    "\n",
    "According to the Kaggle description:\n",
    "> “This dataset, also known as Animal Faces-HQ (AFHQ), consists of 16,130 high-quality images at 512×512 resolution.  \n",
    "> There are three domains of classes, each providing about 5000 images.  \n",
    "> By having multiple (three) domains and diverse images of various breeds per each domain, AFHQ sets a challenging image-to-image translation problem.  \n",
    "> The classes are: Cat, Dog, and Wildlife.”\n",
    "\n",
    "For this project, images are **resized to XxY pixels**, normalized to a [0, 1] range, and converted to **RGB tensors** (three-channel numerical arrays representing red, green, and blue intensities).  \n",
    "These preprocessing steps prepare the data for feature extraction, dimensionality reduction, and clustering.  \n",
    "The dataset’s high resolution, balance across categories, and visual diversity make it well-suited for evaluating **unsupervised image representation learning** and **clustering performance**.\n",
    "\n",
    "![Sample Image Data found in this dataset](../images/2-intro-pic.png)   \n",
    "*Figure: Preview of the dataset used to perform this project.*\n",
    "\n",
    "---\n",
    "\n",
    "#### 1.3 Identify an Unsupervised Learning Problem\n",
    "The goal of this project is to test whether **unsupervised learning algorithms** can **group animal face images into their correct categories** — cats, dogs, and wildlife — **based only on visual similarity**, without using any labels.  \n",
    "In other words, can the models automatically recognize and cluster similar-looking animals together?\n",
    "\n",
    "The analysis includes **exploratory data analysis (EDA)**, visualization of image features using **[t-SNE](https://lvdmaaten.github.io/tsne/)** and **[PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)**, and the application of clustering algorithms such as **[K-Means](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)**, **[DBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html)**, and **[Agglomerative Clustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html)**.  \n",
    "\n",
    "Clustering performance is evaluated using the **[Silhouette Score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html)**, **[Adjusted Rand Index (ARI)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html)**, and **[Normalized Mutual Information (NMI)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.normalized_mutual_info_score.html)**.  \n",
    "\n",
    "By comparing the results of multiple unsupervised models — and contrasting them with a small supervised baseline classifier — this project shows both the **strengths and limitations** of unsupervised learning for basic image classification tasks.  \n",
    "The findings demonstrate how clustering can uncover **hidden visual structure** in data and serve as a foundation for more advanced **self-supervised** or **semi-supervised** learning approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8c843b",
   "metadata": {},
   "source": [
    "### 2. Dataset Overview and Preprocessing\n",
    "\n",
    "#### 2.1 Fetching the Dataset\n",
    "\n",
    "To begin, one must download the dataset (Github does not allow large data to be stored in repo):\n",
    "\n",
    "Git Bash / Linux / WSL:\n",
    "```bash\n",
    "curl -L -o \"$(pwd)/data/animal-faces.zip\" https://www.kaggle.com/api/v1/datasets/download/andrewmvd/animal-faces\n",
    "\n",
    "```\n",
    "\n",
    "After downloading, extract the dataset:\n",
    "```bash\n",
    "unzip \"$(pwd)/data/animal-faces.zip\" -d \"$(pwd)/data/animal-faces\"\n",
    "```\n",
    "\n",
    "To confirm successful extraction, verify that the dataset contains 16,130 images:\n",
    "```bash\n",
    "find \"$(pwd)/data/animal-faces\" -type f | wc -l\n",
    "```\n",
    "\n",
    "**Expected output**:\n",
    "```bash\n",
    "16130\n",
    "```\n",
    "\n",
    "Alternatively, one can simply download the image zip folder from https://www.kaggle.com/datasets/andrewmvd/animal-faces and store it under `~/data` and extract from there as `~/data/animal-faces`\n",
    "With the dataset successfully extracted and verified, the next step involves exploring its structure and visual characteristics through exploratory data analysis (EDA)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4eae00",
   "metadata": {},
   "source": [
    "### 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eb2526",
   "metadata": {},
   "source": [
    "#### 3.1 Initial Inspection\n",
    "\n",
    "This section inspects and visualizes the **Animal Faces-HQ (AFHQ)** dataset to understand its structure, quality, and key characteristics before model building.  \n",
    "The analysis focuses on data composition, visual patterns, feature correlations, preprocessing, and the main insights that will guide the subsequent unsupervised learning experiments.\n",
    "\n",
    "Before applying clustering or dimensionality reduction, it is essential to perform an initial visual inspection of the dataset to gain intuition about its organization and diversity.\n",
    "\n",
    "The dataset is organized into three main categories — **cats**, **dogs**, and **wildlife** — each containing roughly 5,000 high-quality 512×512 images.  \n",
    "Each category includes both training and validation subsets, stored under the following structure:\n",
    "\n",
    "\n",
    "```bash\n",
    "data/\n",
    "├── animal-faces/                # Extracted dataset\n",
    "│   ├── afhq/\n",
    "│       ├── train/\n",
    "│       │   ├── cat/             # ~5,153 images\n",
    "│       │   ├── dog/             # ~4,739 images\n",
    "│       │   └── wild/            # ~4,738 images\n",
    "│       │ \n",
    "│       └── val/\n",
    "│            ├── cat/            # 500 images\n",
    "│            ├── dog/            # 500 images\n",
    "│            └── wild/           # 500 images\n",
    "│\n",
    "└── animal-faces.zip             # Original downloaded dataset archive\n",
    "\n",
    "```\n",
    "\n",
    "#### 3.2 Visual Inspection\n",
    "A few random samples from each class are shown below to demonstrate image quality and diversity.\n",
    "\n",
    "Observations:\n",
    "- The images are **balanced** across categories (≈5,000 per class).  \n",
    "- Each image is **centered and cropped** to focus on the animal’s face.  \n",
    "- There is noticeable variation in lighting, background, and species within each class, which is beneficial for clustering and unsupervised generalization, as the algorithms are exposed to a richer set of visual features to learn from.\n",
    "\n",
    "![Exploring Cat Pic](../images/3-pic.png)   \n",
    "![Exploring Dog Pic](../images/4-pic.png)   \n",
    "![Exploring Wild Pic](../images/5-pic.png)   \n",
    "![Exploring Cat Pic](../images/6-pic.png)   \n",
    "![Exploring Dog Pic](../images/7-pic.png)   \n",
    "![Exploring Wild Pic](../images/8-pic.png)\n",
    "\n",
    "\n",
    "#### 3.3 Dataset Composition and Descriptive Summary\n",
    "\n",
    "#### 3.4 Feature Correlations and Visual Patterns\n",
    "\n",
    "#### 3.5 Data Quality and Cleaning\n",
    "\n",
    "#### 3.6 Transformations and Normalization\n",
    "\n",
    "#### 3.7 Feature Importance and Hypothesis\n",
    "\n",
    "#### 3.8 Summary of EDA Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ae7d5d",
   "metadata": {},
   "source": [
    "### 4. Unsupervised Learning Models and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9210081",
   "metadata": {},
   "source": [
    "### 5. Supervised Baseline (Comparative Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acb3782",
   "metadata": {},
   "source": [
    "### 6. Discussion and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a512d5",
   "metadata": {},
   "source": [
    "### 7. Future Improvements and Areas to Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3aca73",
   "metadata": {},
   "source": [
    "### 8. Summary of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f882f6c",
   "metadata": {},
   "source": [
    "### 9. References and Acknowledgments\n",
    "\n",
    "1. **Animal Faces-HQ (AFHQ) Dataset (Kaggle):**  \n",
    "   https://www.kaggle.com/datasets/andrewmvd/animal-faces\n",
    "\n",
    "2. **Unsupervised Learning Overview:**  \n",
    "   https://biztechmagazine.com/article/2025/05/what-are-benefits-unsupervised-machine-learning-and-clustering-perfcon\n",
    "\n",
    "3. **Applications in Diverse Domains:**  \n",
    "   https://pmc.ncbi.nlm.nih.gov/articles/PMC7983091/\n",
    "\n",
    "4. **Data Exploration and Pattern Discovery:**  \n",
    "   https://analyticalsciencejournals.onlinelibrary.wiley.com/doi/pdfdirect/10.1002/mas.21602\n",
    "\n",
    "5. **Computer Vision Overview:**  \n",
    "   https://viso.ai/deep-learning/supervised-vs-unsupervised-learning/\n",
    "\n",
    "6. **Principal Component Analysis (PCA):**  \n",
    "   https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "\n",
    "7. **SimCLR Paper (Self-Supervised Learning):**  \n",
    "   https://arxiv.org/abs/2002.05709\n",
    "\n",
    "8. **Unsupervised Learning in NLP:**  \n",
    "   https://milvus.io/ai-quick-reference/what-is-the-role-of-unsupervised-learning-in-nlp\n",
    "\n",
    "9. **Word2Vec Paper:**  \n",
    "   https://arxiv.org/abs/1301.3781\n",
    "\n",
    "10. **Latent Dirichlet Allocation (LDA) Paper:**  \n",
    "    https://jmlr.org/papers/v3/blei03a.html\n",
    "\n",
    "11. **Healthcare and Biomedical Applications:**  \n",
    "    https://pubmed.ncbi.nlm.nih.gov/31891765/\n",
    "\n",
    "12. **Autonomous Systems and Robotics:**  \n",
    "    https://fiveable.me/introduction-autonomous-robots/unit-7/unsupervised-learning/study-guide/rNorV1tsC0TeCPOO\n",
    "\n",
    "13. **Recommender and Personalization Systems:**  \n",
    "    https://www.mdpi.com/2073-8994/12/2/185\n",
    "\n",
    "14. **t-SNE Algorithm:**  \n",
    "    https://lvdmaaten.github.io/tsne/\n",
    "\n",
    "15. **PCA (Scikit-learn Implementation):**  \n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "\n",
    "16. **K-Means Clustering:**  \n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "\n",
    "17. **DBSCAN Clustering:**  \n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html\n",
    "\n",
    "18. **Agglomerative Clustering:**  \n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html\n",
    "\n",
    "19. **Silhouette Score:**  \n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html\n",
    "\n",
    "20. **Adjusted Rand Index (ARI):**  \n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html\n",
    "\n",
    "21. **Normalized Mutual Information (NMI):**  \n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.metrics.normalized_mutual_info_score.html"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
